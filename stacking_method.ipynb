{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('./src/analysis')\n",
    "sys.path.append('./src/data_handling')\n",
    "sys.path.append('./src/modeling')\n",
    "sys.path.append('./src/prediction')\n",
    "sys.path.append('./src/visualization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyzer import FeatureAnalyzer\n",
    "from selector import FeatureSelector\n",
    "from aggregator import DataAggregator\n",
    "from feature_engineer import BatteryFeatureEngineer\n",
    "from reader import BatteryDataReader\n",
    "from cross_validator import CrossValidator\n",
    "from evaluator import ModelEvaluator\n",
    "from trainer import ModelTrainer\n",
    "from predictor import Predictor\n",
    "from visualizer import ResultVisualizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation all data --> One dataFrame for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_ids = ['B0005', 'B0006', 'B0007', 'B0018']\n",
    "ACTUAL_DATA_DIR = \"./dataset/\"\n",
    "\n",
    "# Update config for feature engineering\n",
    "fe_configuration = {\n",
    "    # Update config\n",
    "}\n",
    "\n",
    "# Init object\n",
    "aggregator_df = DataAggregator(\n",
    "    battery_ids=battery_ids,\n",
    "    data_dir=ACTUAL_DATA_DIR,\n",
    "    fe_config=fe_configuration\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregator data\n",
    "aggregator_df.aggregate(force_rerun=True)\n",
    "\n",
    "# Get data aggregator\n",
    "df_combined = aggregator_df.get_combined_data()\n",
    "\n",
    "# Check data combined\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESS OUTLIER: Time_CV_phase, Time_CC_phase, Charge_T_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outlier(df_processed,column_names, thresholds):\n",
    "    for column_name, threshold in zip(column_names, thresholds):\n",
    "        indices_below_threshold = df_processed.index[df_processed[column_name] < threshold].tolist()\n",
    "\n",
    "        print(f\"\\nCác index có giá trị < {threshold}: {indices_below_threshold}\")\n",
    "\n",
    "        for idx in indices_below_threshold:\n",
    "            # Kiểm tra xem có phải là hàng cuối cùng không\n",
    "            if idx < len(df_processed) - 1:\n",
    "                value_after = df_processed.loc[idx + 1, column_name]\n",
    "                print(f\" - Tại index {idx}, giá trị gốc là {df_processed.loc[idx, column_name]}.Thay bằng : {value_after}\")\n",
    "                df_processed.loc[idx, column_name] = value_after\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_copy = df_combined.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 636 entries, 0 to 635\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   cycle               636 non-null    int64  \n",
      " 1   capacity            636 non-null    float64\n",
      " 2   SOH                 636 non-null    float64\n",
      " 3   RUL                 636 non-null    int64  \n",
      " 4   Discharge_V_median  636 non-null    float64\n",
      " 5   Discharge_V_skew    636 non-null    float64\n",
      " 6   Discharge_T_delta   636 non-null    float64\n",
      " 7   Discharge_T_std     636 non-null    float64\n",
      " 8   Charge_T_std        636 non-null    float64\n",
      " 9   Time_CC_phase       636 non-null    float64\n",
      " 10  Time_CV_phase       636 non-null    float64\n",
      " 11  CV_I_end            636 non-null    float64\n",
      " 12  battery_id          636 non-null    object \n",
      "dtypes: float64(10), int64(2), object(1)\n",
      "memory usage: 64.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_combined_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = ['Discharge_V_median', 'Discharge_V_skew','Discharge_T_delta','Discharge_T_std','Charge_T_std','Time_CC_phase'\n",
    "                    ,'Time_CV_phase']\n",
    "df_scaled = df_combined_copy.copy()\n",
    "# --- A. StandardScaler ---\n",
    "print(\"\\n--- Sử dụng StandardScaler ---\")\n",
    "scaler_std = StandardScaler()\n",
    "# Fit và transform trực tiếp trên các cột đã chọn của df_scaled\n",
    "df_scaled[features_to_scale] = scaler_std.fit_transform(df_scaled[features_to_scale])\n",
    "print(\"DataFrame sau khi chuẩn hóa bằng StandardScaler:\")\n",
    "print(df_scaled)\n",
    "# In ra mean và std của các cột đã chuẩn hóa để kiểm tra\n",
    "print(\"Mô tả thống kê các cột đã chuẩn hóa (StandardScaler):\")\n",
    "print(df_scaled[features_to_scale].describe().round(2)) # Mean gần 0, std gần 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init object analyzer\n",
    "analyzer = FeatureAnalyzer(combined_data=df_scaled)\n",
    "\n",
    "# Plot heatmap\n",
    "analyzer.plot_correlation_heatmap(figsize=(8, 6), annot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correlation value with SOH and RUL\n",
    "soh_correlation = analyzer.get_correlation_with_target('SOH')\n",
    "\n",
    "print(\"Top 5 Positive/Negative:\")\n",
    "print(soh_correlation.drop('SOH', errors='ignore').head())\n",
    "print(soh_correlation.drop('SOH', errors='ignore').tail())\n",
    "analyzer.plot_correlation_with_target('SOH', sort_by_abs=True, figsize=(8,6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (\n",
    "    LeaveOneGroupOut, GridSearchCV, GroupKFold, KFold\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C_kernel, WhiteKernel\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'SOH'\n",
    "group_column = 'battery_id'\n",
    "cycle_plot_column = 'cycle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns= ['Discharge_V_median', 'Discharge_T_std', 'Charge_T_std', 'Time_CC_phase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled[feature_columns]\n",
    "y = df_scaled[target_column]\n",
    "groups = df_scaled[group_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=150, random_state=42, n_jobs=-1, max_depth=12, min_samples_split=5, min_samples_leaf=3)\n",
    "xgb_model = XGBRegressor(n_estimators=150, random_state=42, n_jobs=-1, objective='reg:squarederror', learning_rate=0.05, max_depth=6, subsample=0.8, colsample_bytree=0.8)\n",
    "svr_model = SVR(kernel='rbf', C=15, epsilon=0.01, gamma='auto') # gamma='auto' or 'scale' or a float\n",
    "gpr_kernel_tuned = C_kernel(1.0, (1e-3, 1e3)) * RBF(length_scale=np.ones(len(feature_columns)), length_scale_bounds=(1e-2, 1e2)) + \\\n",
    "                   WhiteKernel(noise_level=0.05, noise_level_bounds=(1e-10, 1e+1))\n",
    "# Chú ý: length_scale cho RBF trong GPR có thể là một vector (mỗi chiều một length_scale) hoặc một scalar.\n",
    "# Nếu là vector, kích thước phải bằng số lượng features.\n",
    "gpr_model = GaussianProcessRegressor(kernel=gpr_kernel_tuned, random_state=42,\n",
    "                                     alpha=1e-6, # Tham số nhiễu, có thể điều chỉnh\n",
    "                                     n_restarts_optimizer=10, # Để GPR tìm kernel tốt hơn\n",
    "                                     normalize_y=False) # Xem xét normalize_y=True nếu SOH có thang đo rộng\n",
    "\n",
    "base_learners_defs = [\n",
    "    ('rf', rf_model),\n",
    "    ('xgb', xgb_model),\n",
    "    ('svr', svr_model),\n",
    "    ('gpr', gpr_model)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "n_splits = logo.get_n_splits(groups=groups)\n",
    "\n",
    "oof_predictions_base = np.zeros((len(X), len(base_learners_defs)))\n",
    "oof_true_targets_for_meta = np.zeros(len(X)) # Đổi tên để rõ ràng hơn\n",
    "\n",
    "# Tạo một DataFrame để lưu trữ các chỉ số đánh giá của base learners trên từng fold\n",
    "base_learner_metrics_per_fold = []\n",
    "\n",
    "print(f\"\\nBắt đầu quá trình LOBO với {n_splits} pin...\")\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(logo.split(X, y, groups)):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    current_val_battery_id = groups.iloc[val_idx].unique()[0]\n",
    "\n",
    "    print(f\"  Fold {fold_idx + 1}/{n_splits} - Pin đang được bỏ ra để validation: {current_val_battery_id}\")\n",
    "    oof_true_targets_for_meta[val_idx] = y_val_fold.values\n",
    "\n",
    "    for i, (name, model_template) in enumerate(base_learners_defs):\n",
    "        print(f\"    Đang huấn luyện base learner: {name} cho pin {current_val_battery_id}\")\n",
    "        model_instance = clone(model_template)\n",
    "        fold_preds = np.full(len(X_val_fold), np.nan) # Khởi tạo dự đoán là NaN\n",
    "        r2 = np.nan\n",
    "        mae = np.nan\n",
    "        rmse = np.nan\n",
    "\n",
    "        try:\n",
    "            if X_train_fold.empty and name == 'gpr':\n",
    "                 raise ValueError(\"X_train_fold rỗng, không thể huấn luyện GPR\")\n",
    "            model_instance.fit(X_train_fold, y_train_fold)\n",
    "            fold_preds_success = model_instance.predict(X_val_fold)\n",
    "            fold_preds = fold_preds_success # Gán lại nếu thành công\n",
    "\n",
    "            # Tính toán các chỉ số nếu dự đoán thành công\n",
    "            r2 = r2_score(y_val_fold, fold_preds)\n",
    "            mae = mean_absolute_error(y_val_fold, fold_preds)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val_fold, fold_preds))\n",
    "\n",
    "            print(f\"      {name} - Pin {current_val_battery_id}: R2={r2:.4f}, MAE={mae:.4f}, RMSE={rmse:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    LỖI khi huấn luyện/dự đoán với {name}: {e}\")\n",
    "            # fold_preds đã được khởi tạo là NaN, các metrics cũng là NaN\n",
    "\n",
    "        oof_predictions_base[val_idx, i] = fold_preds\n",
    "        base_learner_metrics_per_fold.append({\n",
    "            'fold': fold_idx + 1,\n",
    "            'battery_id_val': current_val_battery_id,\n",
    "            'base_learner': name,\n",
    "            'R2': r2,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse\n",
    "        })\n",
    "\n",
    "print(\"\\nHoàn thành tạo OOF predictions cho base learners.\")\n",
    "\n",
    "# Chuyển danh sách metrics thành DataFrame để dễ xem và phân tích\n",
    "metrics_df = pd.DataFrame(base_learner_metrics_per_fold)\n",
    "print(\"\\n--- Chỉ số đánh giá của Base Learners trên từng Fold (LOBO) ---\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Tính trung bình các chỉ số cho mỗi base learner qua các fold\n",
    "print(\"\\n--- Chỉ số đánh giá trung bình của Base Learners qua các Folds ---\")\n",
    "avg_metrics_df = metrics_df.groupby('base_learner')[['R2', 'MAE', 'RMSE']].mean()\n",
    "print(avg_metrics_df)\n",
    "\n",
    "\n",
    "meta_features_from_oof = pd.DataFrame(oof_predictions_base, columns=[name for name, _ in base_learners_defs])\n",
    "for col in meta_features_from_oof.columns:\n",
    "    if meta_features_from_oof[col].isnull().any():\n",
    "        print(f\"Cảnh báo: Tìm thấy NaN trong OOF predictions của {col}. Điền bằng giá trị trung bình.\")\n",
    "        if not meta_features_from_oof[col].isnull().all():\n",
    "            mean_val = meta_features_from_oof[col].mean()\n",
    "            meta_features_from_oof[col].fillna(mean_val, inplace=True)\n",
    "        else:\n",
    "            print(f\"Cảnh báo: Tất cả giá trị trong OOF predictions của {col} là NaN. Điền bằng 0.\")\n",
    "            meta_features_from_oof[col].fillna(0, inplace=True)\n",
    "\n",
    "meta_target_for_training = pd.Series(oof_true_targets_for_meta, name=target_column) # Sử dụng tên đã đổi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>svr</th>\n",
       "      <th>gpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.194848</td>\n",
       "      <td>93.751877</td>\n",
       "      <td>91.567688</td>\n",
       "      <td>98.942341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.224818</td>\n",
       "      <td>93.412331</td>\n",
       "      <td>93.653407</td>\n",
       "      <td>97.639135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.226922</td>\n",
       "      <td>94.548561</td>\n",
       "      <td>94.114095</td>\n",
       "      <td>95.789206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.322875</td>\n",
       "      <td>94.510292</td>\n",
       "      <td>93.989391</td>\n",
       "      <td>94.885128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.322875</td>\n",
       "      <td>94.622269</td>\n",
       "      <td>94.503118</td>\n",
       "      <td>95.257396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95.806021</td>\n",
       "      <td>97.059509</td>\n",
       "      <td>95.650261</td>\n",
       "      <td>96.683702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95.613442</td>\n",
       "      <td>97.106674</td>\n",
       "      <td>95.884539</td>\n",
       "      <td>96.341686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>92.365779</td>\n",
       "      <td>93.222748</td>\n",
       "      <td>93.341512</td>\n",
       "      <td>90.729224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>92.536035</td>\n",
       "      <td>93.554947</td>\n",
       "      <td>93.689762</td>\n",
       "      <td>90.885602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92.552898</td>\n",
       "      <td>93.584930</td>\n",
       "      <td>93.849914</td>\n",
       "      <td>91.105856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rf        xgb        svr        gpr\n",
       "0  92.194848  93.751877  91.567688  98.942341\n",
       "1  93.224818  93.412331  93.653407  97.639135\n",
       "2  93.226922  94.548561  94.114095  95.789206\n",
       "3  93.322875  94.510292  93.989391  94.885128\n",
       "4  93.322875  94.622269  94.503118  95.257396\n",
       "5  95.806021  97.059509  95.650261  96.683702\n",
       "6  95.613442  97.106674  95.884539  96.341686\n",
       "7  92.365779  93.222748  93.341512  90.729224\n",
       "8  92.536035  93.554947  93.689762  90.885602\n",
       "9  92.552898  93.584930  93.849914  91.105856"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_features_from_oof.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# META MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_ridge_template = Ridge(alpha=0.5, random_state=42, solver='auto')\n",
    "trained_meta_learner = clone(meta_learner_ridge_template)\n",
    "\n",
    "print(\"\\nĐang huấn luyện meta-learner (Ridge Regression)...\")\n",
    "trained_meta_learner.fit(meta_features_from_oof, meta_target_for_training)\n",
    "print(\"Hoàn thành huấn luyện meta-learner.\")\n",
    "print(\"\\nHệ số của meta-learner (Ridge Regression):\")\n",
    "for name, coef in zip(meta_features_from_oof.columns, trained_meta_learner.coef_):\n",
    "    print(f\"  {name}: {coef:.4f}\")\n",
    "\n",
    "# --- BƯỚC 4: ĐÁNH GIÁ VÀ VẼ ĐỒ THỊ CHO META-LEARNER TRÊN OOF PREDICTIONS ---\n",
    "stacking_oof_predictions = trained_meta_learner.predict(meta_features_from_oof)\n",
    "oof_rmse_stacking = np.sqrt(mean_squared_error(meta_target_for_training, stacking_oof_predictions))\n",
    "oof_r2_stacking = r2_score(meta_target_for_training, stacking_oof_predictions)\n",
    "oof_mae_stacking = mean_absolute_error(meta_target_for_training, stacking_oof_predictions) # Thêm MAE cho stacking\n",
    "print(f\"\\n--- Chỉ số đánh giá của Mô hình STACKING trên OOF predictions (tổng thể) ---\")\n",
    "print(f\"  RMSE: {oof_rmse_stacking:.4f}\")\n",
    "print(f\"  R2 score: {oof_r2_stacking:.4f}\")\n",
    "print(f\"  MAE: {oof_mae_stacking:.4f}\")\n",
    "\n",
    "\n",
    "# Vẽ đồ thị cho meta-learner (giữ nguyên phần này vì nó hữu ích)\n",
    "fig_meta_learner, axes_meta_learner = plt.subplots(n_splits, 1,\n",
    "                                                   figsize=(8, 15),\n",
    "                                                   sharey=True, constrained_layout=True)\n",
    "if n_splits == 1:\n",
    "    axes_meta_learner = [axes_meta_learner]\n",
    "fig_meta_learner.suptitle('Meta Learner (Stacking) Predictions vs Actual (trên OOF data, theo Pin)', fontsize=18, y=1.03)\n",
    "unique_batteries = groups.unique()\n",
    "for i, battery_id_to_plot in enumerate(unique_batteries):\n",
    "    battery_mask = (groups == battery_id_to_plot).values\n",
    "    x_plot_values_batt = df_scaled[battery_mask][cycle_plot_column].values\n",
    "    actual_batt = meta_target_for_training[battery_mask]\n",
    "    predicted_batt_stacking = stacking_oof_predictions[battery_mask]\n",
    "    ax_meta = axes_meta_learner[i]\n",
    "    ax_meta.plot(x_plot_values_batt, actual_batt, label='Actual SOH', marker='.', linestyle='-', markersize=6)\n",
    "    ax_meta.plot(x_plot_values_batt, predicted_batt_stacking, label='Stacking Predicted SOH', marker='x', linestyle='--', markersize=6)\n",
    "    ax_meta.set_title(f'Stacking Model - Pin: {battery_id_to_plot}', fontsize=12)\n",
    "    ax_meta.set_xlabel(cycle_plot_column, fontsize=10)\n",
    "    ax_meta.set_ylabel('SOH', fontsize=10)\n",
    "    ax_meta.legend(fontsize=9)\n",
    "    ax_meta.grid(True, linestyle=':', alpha=0.5)\n",
    "    ax_meta.tick_params(axis='both', which='major', labelsize=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BƯỚC 5: XÂY DỰNG MÔ HÌNH STACKING CUỐI CÙNG ĐỂ DỰ ĐOÁN TRÊN DỮ LIỆU MỚI ---\n",
    "# (Class FinalStackingRegressor giữ nguyên như trước)\n",
    "class FinalStackingRegressor:\n",
    "    def __init__(self, base_learner_templates_list, meta_learner_template_model):\n",
    "        self.base_learner_templates_list = base_learner_templates_list\n",
    "        self.meta_learner_template_model = meta_learner_template_model\n",
    "        self.trained_base_learners_ = []\n",
    "        self.trained_meta_learner_ = None\n",
    "        self.active_base_learner_names_ = []\n",
    "\n",
    "    def fit(self, X_all_train_data, y_all_train_data, X_meta_features_oof_data, y_meta_target_oof_data):\n",
    "        print(\"Đang huấn luyện lại các base learner trên TOÀN BỘ dữ liệu huấn luyện gốc...\")\n",
    "        self.trained_base_learners_ = []\n",
    "        self.active_base_learner_names_ = []\n",
    "        for name, model_template_item in self.base_learner_templates_list:\n",
    "            print(f\"  Huấn luyện {name}...\")\n",
    "            model_instance_item = clone(model_template_item)\n",
    "            try:\n",
    "                if X_all_train_data.empty and name == 'gpr':\n",
    "                    raise ValueError(\"X_all_train_data rỗng, không thể huấn luyện GPR\")\n",
    "                model_instance_item.fit(X_all_train_data, y_all_train_data)\n",
    "                self.trained_base_learners_.append(model_instance_item)\n",
    "                self.active_base_learner_names_.append(name)\n",
    "            except Exception as e:\n",
    "                print(f\"    LỖI khi huấn luyện lại {name} trên toàn bộ dữ liệu: {e}. Base learner này sẽ bị bỏ qua.\")\n",
    "        print(f\"Hoàn thành huấn luyện {len(self.trained_base_learners_)} base learners.\")\n",
    "\n",
    "        print(\"\\nĐang huấn luyện meta-learner trên dữ liệu OOF...\")\n",
    "        self.trained_meta_learner_ = clone(self.meta_learner_template_model)\n",
    "        self.trained_meta_learner_.fit(X_meta_features_oof_data, y_meta_target_oof_data)\n",
    "        print(\"Hoàn thành huấn luyện meta-learner.\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_new_data):\n",
    "        if not self.trained_base_learners_ or self.trained_meta_learner_ is None:\n",
    "            raise ValueError(\"Mô hình Stacking chưa được huấn luyện đầy đủ. Gọi fit() trước.\")\n",
    "        if not self.active_base_learner_names_:\n",
    "             raise ValueError(\"Không có base learner nào được huấn luyện thành công trong mô hình cuối cùng.\")\n",
    "\n",
    "        print(\"Tạo dự đoán từ các base learner cho dữ liệu mới...\")\n",
    "        base_predictions_new_data = np.zeros((len(X_new_data), len(self.trained_base_learners_)))\n",
    "        for i, model_instance_item in enumerate(self.trained_base_learners_):\n",
    "            base_predictions_new_data[:, i] = model_instance_item.predict(X_new_data)\n",
    "        meta_features_new_data = pd.DataFrame(base_predictions_new_data, columns=self.active_base_learner_names_)\n",
    "\n",
    "        print(\"Tạo dự đoán cuối cùng từ meta-learner...\")\n",
    "        final_predictions_result = self.trained_meta_learner_.predict(meta_features_new_data)\n",
    "        return final_predictions_result\n",
    "\n",
    "final_stacking_model_instance = FinalStackingRegressor(\n",
    "    base_learner_templates_list=base_learners_defs,\n",
    "    meta_learner_template_model=meta_learner_ridge_template\n",
    ")\n",
    "final_stacking_model_instance.fit(\n",
    "    X_all_train_data=X, y_all_train_data=y,\n",
    "    X_meta_features_oof_data=meta_features_from_oof, y_meta_target_oof_data=meta_target_for_training\n",
    ")\n",
    "\n",
    "# ---- GIẢ LẬP DỮ LIỆU TEST MỚI ĐỂ DỰ ĐOÁN VÀ VẼ ĐỒ THỊ ----\n",
    "n_test_samples = 50\n",
    "X_test_new_demo = pd.DataFrame(np.random.normal(0, 0.5, (n_test_samples, len(feature_columns))), columns=feature_columns)\n",
    "test_cycles_original = np.arange(1, n_test_samples + 1)\n",
    "y_test_actual_demo = 1 - (test_cycles_original / (n_test_samples * 1.8)) - np.random.normal(0, 0.02, n_test_samples)\n",
    "y_test_actual_demo = np.clip(y_test_actual_demo, 0.65, 1.0)\n",
    "X_test_new_demo[cycle_plot_column] = test_cycles_original\n",
    "\n",
    "predictions_on_new_data = final_stacking_model_instance.predict(X_test_new_demo[feature_columns])\n",
    "\n",
    "# Đánh giá trên tập test mới (nếu có y_test_actual_demo)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_actual_demo, predictions_on_new_data))\n",
    "test_r2 = r2_score(y_test_actual_demo, predictions_on_new_data)\n",
    "test_mae = mean_absolute_error(y_test_actual_demo, predictions_on_new_data)\n",
    "print(f\"\\n--- Chỉ số đánh giá của Mô hình STACKING trên DỮ LIỆU TEST MỚI ---\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R2 score: {test_r2:.4f}\")\n",
    "print(f\"  MAE: {test_mae:.4f}\")\n",
    "\n",
    "# Vẽ đồ thị cho dữ liệu test (giữ nguyên)\n",
    "fig_test, ax_test = plt.subplots(figsize=(12, 7))\n",
    "ax_test.plot(X_test_new_demo[cycle_plot_column], y_test_actual_demo, label='Actual SOH (Test Data)', marker='.', linestyle='-', markersize=7)\n",
    "ax_test.plot(X_test_new_demo[cycle_plot_column], predictions_on_new_data, label='Stacking Predicted SOH (Test Data)', marker='x', linestyle='--', markersize=7)\n",
    "ax_test.set_title('Stacking Model Predictions vs Actual on New Test Data', fontsize=14)\n",
    "ax_test.set_xlabel(cycle_plot_column, fontsize=12)\n",
    "ax_test.set_ylabel('SOH', fontsize=12)\n",
    "ax_test.legend(fontsize=10)\n",
    "ax_test.grid(True, linestyle=':', alpha=0.6)\n",
    "ax_test.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tối ưu hóa tham số mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Định nghĩa các nhóm/cấp độ siêu tham số cho từng base learner ---\n",
    "\n",
    "param_levels = {\n",
    "    'rf': {\n",
    "        'simple': {\n",
    "            'n_estimators': [100],\n",
    "            'max_depth': [5, 10],\n",
    "            'min_samples_split': [10],\n",
    "            'min_samples_leaf': [5],\n",
    "            'max_features': ['sqrt']\n",
    "        },\n",
    "        'moderate': {\n",
    "            'n_estimators': [150, 200],\n",
    "            'max_depth': [10, 15], # None cho phép cây phát triển đầy đủ\n",
    "            'min_samples_split': [5, 10],\n",
    "            'min_samples_leaf': [2, 4],\n",
    "            'max_features': ['sqrt']\n",
    "        },\n",
    "        'complex': {\n",
    "            'n_estimators': [200, 300],\n",
    "            'max_depth': [15, 20],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 2],\n",
    "            'max_features': ['sqrt'] # Thử cả tỷ lệ feature\n",
    "        },\n",
    "        'very_complex': {\n",
    "            'n_estimators': [300, 500],\n",
    "            'max_depth': [20, 30],\n",
    "            'min_samples_split': [2],\n",
    "            'min_samples_leaf': [1],\n",
    "            'max_features': ['sqrt'] # 'auto' = all features\n",
    "        }\n",
    "    },\n",
    "    'xgb': {\n",
    "        'simple': {\n",
    "            'n_estimators': [100],\n",
    "            'learning_rate': [0.1],\n",
    "            'max_depth': [3, 5],\n",
    "            'subsample': [0.8],\n",
    "            'colsample_bytree': [0.8],\n",
    "            'gamma': [0, 0.1]\n",
    "        },\n",
    "        'moderate': {\n",
    "            'n_estimators': [150, 200],\n",
    "            'learning_rate': [0.05],\n",
    "            'max_depth': [5, 7],\n",
    "            'subsample': [0.7, 0.8],\n",
    "            'colsample_bytree': [0.7, 0.8],\n",
    "            'gamma': [0, 0.1],\n",
    "            'reg_alpha': [0, 0.01],\n",
    "            'reg_lambda': [1, 0.1] # Lambda thường > Alpha\n",
    "        },\n",
    "        'complex': {\n",
    "            'n_estimators': [200, 300],\n",
    "            'learning_rate': [0.01], # Learning rate nhỏ hơn với nhiều cây hơn\n",
    "            'max_depth': [7, 9],\n",
    "            'subsample': [0.6, 0.7],\n",
    "            'colsample_bytree': [0.6, 0.7],\n",
    "            'gamma': [0.1, 0.2],\n",
    "            'reg_alpha': [0.01, 0.1],\n",
    "            'reg_lambda': [0.1, 0.5]\n",
    "        },\n",
    "        'very_complex': {\n",
    "            'n_estimators': [300, 500],\n",
    "            'learning_rate': [0.01],\n",
    "            'max_depth': [9, 12],\n",
    "            'subsample': [0.5, 0.6],\n",
    "            'colsample_bytree': [0.5, 0.6],\n",
    "            'gamma': [0.2, 0.5],\n",
    "            'reg_alpha': [0.1, 0.5],\n",
    "            'reg_lambda': [0.5, 1]\n",
    "        }\n",
    "    },\n",
    "    'svr': {\n",
    "        'simple': {\n",
    "            'C': [1, 10],\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'gamma': ['scale'], # 'scale' là lựa chọn an toàn\n",
    "            'epsilon': [0.1]\n",
    "        },\n",
    "        'moderate': {\n",
    "            'C': [10, 50],\n",
    "            'kernel': ['rbf', 'poly'],\n",
    "            'gamma': ['scale', 'auto', 0.01],\n",
    "            'epsilon': [0.05, 0.1],\n",
    "            'degree': [2, 3] # Cho poly\n",
    "        },\n",
    "        'complex': {\n",
    "            'C': [50, 100],\n",
    "            'kernel': ['rbf', 'poly'],\n",
    "            'gamma': [0.001, 0.01, 0.1], # Giá trị gamma cụ thể\n",
    "            'epsilon': [0.01, 0.05],\n",
    "            'degree': [3, 4]\n",
    "        },\n",
    "        'very_complex': {\n",
    "            'C': [100, 200],\n",
    "            'kernel': ['rbf'], # RBF thường linh hoạt nhất\n",
    "            'gamma': [0.0001, 0.001, 0.01],\n",
    "            'epsilon': [0.005, 0.01],\n",
    "            # 'degree' không cần nếu chỉ dùng RBF\n",
    "        }\n",
    "    },\n",
    "    'gpr': {\n",
    "        # Tinh chỉnh GPR kernel phức tạp hơn, cần định nghĩa các kernel ứng viên\n",
    "        # Ở đây, chúng ta sẽ tập trung vào các tham số alpha và n_restarts\n",
    "        # và giả sử bạn sẽ định nghĩa một vài kernel candidates riêng\n",
    "        'simple': {\n",
    "            # 'kernel': [kernel_simple_1, kernel_simple_2], # Bạn cần định nghĩa các kernel này\n",
    "            'alpha': [1e-5, 1e-3],\n",
    "            'n_restarts_optimizer': [5]\n",
    "        },\n",
    "        'moderate': {\n",
    "            # 'kernel': [kernel_moderate_1, kernel_moderate_2],\n",
    "            'alpha': [1e-7, 1e-5],\n",
    "            'n_restarts_optimizer': [10]\n",
    "        },\n",
    "        'complex': {\n",
    "            # 'kernel': [kernel_complex_1, kernel_complex_2],\n",
    "            'alpha': [1e-9, 1e-7],\n",
    "            'n_restarts_optimizer': [15]\n",
    "        },\n",
    "        'very_complex': {\n",
    "            # 'kernel': [kernel_very_complex_1, kernel_very_complex_2],\n",
    "            'alpha': [1e-10, 1e-9],\n",
    "            'n_restarts_optimizer': [20]\n",
    "        }\n",
    "    },\n",
    "    'ridge': { # Siêu tham số cho Meta-Learner (Ridge Regression)\n",
    "        'simple': {'alpha': [1.0, 5.0, 10.0]},\n",
    "        'moderate': {'alpha': [0.1, 0.5, 1.0, 2.0]},\n",
    "        'complex': {'alpha': [0.01, 0.05, 0.1, 0.5]}, # Alpha nhỏ hơn cho phép phức tạp hơn\n",
    "        'very_complex': {'alpha': [0.001, 0.005, 0.01, 0.05]}\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ví dụ tham số GPR 'moderate' sau khi thêm kernel và alpha/n_restarts:\n",
      "{'alpha': [1e-07, 1e-05], 'n_restarts_optimizer': [10], 'kernel': [1**2 * RBF(length_scale=[1, 1, 1, 1, 1, 1, 1]) + WhiteKernel(noise_level=0.05), 1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=1.5) + WhiteKernel(noise_level=0.05), 1**2 * RationalQuadratic(alpha=0.1, length_scale=1) + WhiteKernel(noise_level=0.05)]}\n"
     ]
    }
   ],
   "source": [
    "# --- Cấp độ 'simple' ---\n",
    "num_features = 7\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "    RBF,\n",
    "    Matern,\n",
    "    RationalQuadratic,\n",
    "    ExpSineSquared,\n",
    "    DotProduct,\n",
    "    ConstantKernel as C, # Đổi tên để tránh nhầm lẫn với hằng số C của SVR\n",
    "    WhiteKernel,\n",
    "    PairwiseKernel # Cho phép sử dụng các kernel của scikit-learn như linear, rbf, poly\n",
    ")\n",
    "# Kernel RBF đơn giản với length_scale vô hướng (isotropic)\n",
    "kernel_gpr_simple_rbf = C(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) + \\\n",
    "                        WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-5, 1e1))\n",
    "\n",
    "# Kernel Matern đơn giản (nu=1.5 là một lựa chọn phổ biến, ít \"mượt\" hơn RBF)\n",
    "kernel_gpr_simple_matern = C(1.0, (1e-3, 1e3)) * Matern(length_scale=1.0, length_scale_bounds=(1e-2, 1e2), nu=1.5) + \\\n",
    "                           WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-5, 1e1))\n",
    "\n",
    "# --- Cấp độ 'moderate' ---\n",
    "# Kernel RBF với length_scale riêng cho từng chiều (anisotropic)\n",
    "# Điều này rất quan trọng nếu các feature có thang đo hoặc tầm quan trọng khác nhau.\n",
    "kernel_gpr_moderate_rbf_aniso = C(1.0, (1e-3, 1e3)) * RBF(length_scale=np.ones(num_features), length_scale_bounds=(1e-2, 1e2)) + \\\n",
    "                                WhiteKernel(noise_level=0.05, noise_level_bounds=(1e-5, 1e1))\n",
    "\n",
    "# Kernel Matern anisotropic\n",
    "kernel_gpr_moderate_matern_aniso = C(1.0, (1e-3, 1e3)) * Matern(length_scale=np.ones(num_features), length_scale_bounds=(1e-2, 1e2), nu=1.5) + \\\n",
    "                                   WhiteKernel(noise_level=0.05, noise_level_bounds=(1e-5, 1e1))\n",
    "\n",
    "# Kernel Rational Quadratic (có thể nắm bắt các biến đổi ở nhiều thang đo)\n",
    "kernel_gpr_moderate_rq = C(1.0, (1e-3, 1e3)) * RationalQuadratic(length_scale=1.0, alpha=0.1, length_scale_bounds=(1e-2,1e2), alpha_bounds=(1e-2,1e2)) + \\\n",
    "                         WhiteKernel(noise_level=0.05, noise_level_bounds=(1e-5, 1e1))\n",
    "\n",
    "# --- Cấp độ 'complex' ---\n",
    "# Kết hợp RBF anisotropic và một kernel DotProduct (tuyến tính)\n",
    "# Có thể hữu ích nếu có cả thành phần phi tuyến và tuyến tính trong dữ liệu\n",
    "kernel_gpr_complex_rbf_dot = C(1.0) * RBF(length_scale=np.ones(num_features), length_scale_bounds=(1e-1, 1e1)) + \\\n",
    "                             C(1.0) * DotProduct(sigma_0=1.0, sigma_0_bounds=(1e-2, 1e2)) + \\\n",
    "                             WhiteKernel(noise_level=0.01, noise_level_bounds=(1e-5, 1e0))\n",
    "\n",
    "# Kernel RBF với length_scale bounds chặt hơn, cho phép tinh chỉnh kỹ hơn\n",
    "kernel_gpr_complex_rbf_tight_bounds = C(1.0, (1e-2, 1e2)) * RBF(length_scale=np.ones(num_features), length_scale_bounds=(1e-1, 1e1)) + \\\n",
    "                                      WhiteKernel(noise_level=0.01, noise_level_bounds=(1e-5, 1e0))\n",
    "\n",
    "\n",
    "# Kernel ExpSineSquared (cho dữ liệu có tính chu kỳ, có thể không phù hợp lắm với SOH trừ khi có yếu tố chu kỳ mạnh)\n",
    "# Ở đây chỉ để minh họa sự đa dạng. Cần điều chỉnh `periodicity`.\n",
    "# kernel_gpr_complex_expsine = C(1.0) * ExpSineSquared(length_scale=1.0, periodicity=10.0, # periodicity cần được ước lượng từ dữ liệu\n",
    "# length_scale_bounds=(1e-1,1e1), periodicity_bounds=(1.0, 50.0)\n",
    "#                                                       ) + \\\n",
    "#                              WhiteKernel(noise_level=0.01)\n",
    "\n",
    "# --- Cấp độ 'very_complex' ---\n",
    "# Một kernel phức tạp hơn bằng cách cộng nhiều thành phần RBF với các length_scale khác nhau (ARD - Automatic Relevance Determination)\n",
    "# Điều này cho phép mô hình nắm bắt các cấu trúc ở các \"tần số\" khác nhau.\n",
    "kernel_gpr_very_complex_sum_rbf = C(1.0) * RBF(length_scale=np.ones(num_features)*0.5, length_scale_bounds=(1e-2, 1e1)) + \\\n",
    "                                  C(1.0) * RBF(length_scale=np.ones(num_features)*2.0, length_scale_bounds=(1e-1, 1e2)) + \\\n",
    "                                  WhiteKernel(noise_level=0.005, noise_level_bounds=(1e-6, 1e-1))\n",
    "\n",
    "# Kết hợp Matern (nu=2.5, mượt hơn nu=1.5) với một thành phần tuyến tính\n",
    "kernel_gpr_very_complex_matern_dot = C(1.0) * Matern(length_scale=np.ones(num_features), nu=2.5, length_scale_bounds=(1e-2, 1e1)) + \\\n",
    "                                     C(1.0) * DotProduct(sigma_0=0.5, sigma_0_bounds=(1e-3, 1e1)) + \\\n",
    "                                     WhiteKernel(noise_level=0.005, noise_level_bounds=(1e-6, 1e-1))\n",
    "\n",
    "# Sử dụng PairwiseKernel để bọc một kernel RBF từ scikit-learn (chỉ để minh họa, thường dùng RBF trực tiếp của GPR tốt hơn)\n",
    "# from sklearn.metrics.pairwise import rbf_kernel\n",
    "# kernel_gpr_very_complex_pairwise = C(1.0) * PairwiseKernel(gamma=0.1, metric='rbf') + \\\n",
    "# WhiteKernel(noise_level=0.005)\n",
    "\n",
    "# --- Cập nhật param_levels['gpr']['kernel'] ---\n",
    "# Tạo một kernel mặc định an toàn phòng trường hợp num_features không đúng\n",
    "default_gpr_kernel = C(1.0) * RBF(length_scale=1.0) + WhiteKernel(noise_level=0.1)\n",
    "\n",
    "if 'param_levels' not in globals(): # Nếu param_levels chưa được định nghĩa ở đâu đó\n",
    "    param_levels = {'gpr': {level: {} for level in ['simple', 'moderate', 'complex', 'very_complex']}}\n",
    "\n",
    "\n",
    "param_levels['gpr']['simple']['kernel'] = [kernel_gpr_simple_rbf, kernel_gpr_simple_matern]\n",
    "param_levels['gpr']['moderate']['kernel'] = [kernel_gpr_moderate_rbf_aniso, kernel_gpr_moderate_matern_aniso, kernel_gpr_moderate_rq]\n",
    "param_levels['gpr']['complex']['kernel'] = [kernel_gpr_moderate_rbf_aniso, kernel_gpr_moderate_matern_aniso, kernel_gpr_moderate_rq]# Bỏ ExpSine nếu không chắc\n",
    "param_levels['gpr']['very_complex']['kernel'] = [kernel_gpr_moderate_rbf_aniso, kernel_gpr_moderate_matern_aniso, kernel_gpr_moderate_rq]\n",
    "\n",
    "# Đảm bảo các cấp độ GPR khác trong param_levels cũng được khởi tạo nếu cần\n",
    "for model_name in ['rf', 'xgb', 'svr', 'ridge']:\n",
    "    if model_name not in param_levels:\n",
    "        param_levels[model_name] = {level: {} for level in ['simple', 'moderate', 'complex', 'very_complex']}\n",
    "\n",
    "\n",
    "\n",
    "if 'param_levels' in globals(): # Chỉ chạy nếu param_levels đã được định nghĩa\n",
    "    param_levels['gpr']['simple'].update({\n",
    "        'alpha': [1e-5, 1e-3],\n",
    "        'n_restarts_optimizer': [5]\n",
    "    })\n",
    "    param_levels['gpr']['moderate'].update({\n",
    "        'alpha': [1e-7, 1e-5],\n",
    "        'n_restarts_optimizer': [10]\n",
    "    })\n",
    "    param_levels['gpr']['complex'].update({\n",
    "        'alpha': [1e-9, 1e-7],\n",
    "        'n_restarts_optimizer': [15]\n",
    "    })\n",
    "    param_levels['gpr']['very_complex'].update({\n",
    "        'alpha': [1e-10, 1e-9],\n",
    "        'n_restarts_optimizer': [20]\n",
    "    })\n",
    "\n",
    "    # In ra để kiểm tra một cấp độ\n",
    "    print(\"\\nVí dụ tham số GPR 'moderate' sau khi thêm kernel và alpha/n_restarts:\")\n",
    "    print(param_levels['gpr']['moderate'])\n",
    "\n",
    "else:\n",
    "    print(\"Cảnh báo: 'param_levels' chưa được định nghĩa. Không thể cập nhật alpha và n_restarts cho GPR.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BƯỚC 1: KHỞI TẠO BASE LEARNERS (CHỈ LÀ TEMPLATE BAN ĐẦU) ---\n",
    "rf_model_template = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "xgb_model_template = XGBRegressor(random_state=42, n_jobs=-1, objective='reg:squarederror')\n",
    "svr_model_template = SVR()\n",
    "gpr_model_template = GaussianProcessRegressor(random_state=42) # Kernel sẽ được set bởi GridSearchCV\n",
    "\n",
    "base_learner_templates = [ # Danh sách các template ban đầu\n",
    "    ('rf', rf_model_template),\n",
    "    ('xgb', xgb_model_template),\n",
    "    ('svr', svr_model_template),\n",
    "    ('gpr', gpr_model_template)\n",
    "]\n",
    "# Nếu không có feature, loại bỏ GPR\n",
    "if num_features == 0 and 'gpr' in [name for name,_ in base_learner_templates]:\n",
    "    base_learner_templates = [tpl for tpl in base_learner_templates if tpl[0] != 'gpr']\n",
    "    print(\"CẢNH BÁO: GPR đã bị loại bỏ do không có features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BƯỚC 2: TẠO OUT-OF-FOLD (OOF) PREDICTIONS VỚI GridSearchCV (NESTED CV) ---\n",
    "logo_outer = LeaveOneGroupOut() # Outer loop: LOBO theo pin\n",
    "n_outer_splits = logo_outer.get_n_splits(groups=groups)\n",
    "\n",
    "oof_predictions_base = np.zeros((len(X), len(base_learner_templates)))\n",
    "oof_true_targets_for_meta = np.zeros(len(X))\n",
    "best_params_per_fold_learner = [] # Lưu trữ best_params cho từng base learner ở mỗi outer fold\n",
    "\n",
    "# CHỌN CẤP ĐỘ THAM SỐ ĐỂ THỬ NGHIỆM (ví dụ: chỉ 'simple' để chạy nhanh)\n",
    "# Nếu muốn thử tất cả: levels_to_try = ['simple', 'moderate', 'complex', 'very_complex']\n",
    "current_level_to_try = 'moderate'\n",
    "print(f\"\\n--- SỬ DỤNG CẤP ĐỘ THAM SỐ: {current_level_to_try.upper()} ---\")\n",
    "\n",
    "\n",
    "print(f\"\\nBắt đầu quá trình Nested LOBO với {n_outer_splits} pin (Outer Loop)...\")\n",
    "start_time_total_lobo = time.time()\n",
    "\n",
    "for fold_idx_outer, (train_idx_outer, val_idx_outer) in enumerate(logo_outer.split(X, y, groups)):\n",
    "    X_train_outer, X_val_outer = X.iloc[train_idx_outer], X.iloc[val_idx_outer]\n",
    "    y_train_outer, y_val_outer = y.iloc[train_idx_outer], y.iloc[val_idx_outer]\n",
    "    groups_train_outer = groups.iloc[train_idx_outer] # Groups cho inner CV\n",
    "    current_val_battery_id = groups.iloc[val_idx_outer].unique()[0]\n",
    "\n",
    "    print(f\"\\n  Outer Fold {fold_idx_outer + 1}/{n_outer_splits} - Pin VAL: {current_val_battery_id}\")\n",
    "    oof_true_targets_for_meta[val_idx_outer] = y_val_outer.values\n",
    "\n",
    "    for i_learner, (learner_name, model_template) in enumerate(base_learner_templates):\n",
    "        start_time_learner_fold = time.time()\n",
    "        print(f\"    Tinh chỉnh và huấn luyện Base Learner: {learner_name}\")\n",
    "\n",
    "        # Lấy param grid cho learner và level hiện tại\n",
    "        if learner_name not in param_levels or current_level_to_try not in param_levels[learner_name]:\n",
    "            print(f\"Cảnh báo: Không tìm thấy param grid cho {learner_name} ở level {current_level_to_try}. Bỏ qua.\")\n",
    "            oof_predictions_base[val_idx_outer, i_learner] = np.nan # Gán NaN nếu không có param grid\n",
    "            continue\n",
    "\n",
    "        param_grid_learner = param_levels[learner_name][current_level_to_try]\n",
    "\n",
    "        # Inner CV: GroupKFold nếu có nhiều hơn 1 pin trong X_train_outer, ngược lại KFold\n",
    "        # Giảm số fold của inner CV để chạy nhanh hơn khi test\n",
    "        n_inner_cv_splits = min(3, len(groups_train_outer.unique())) if len(groups_train_outer.unique()) > 1 else 2\n",
    "        if len(groups_train_outer.unique()) > 1 :\n",
    "            inner_cv = GroupKFold(n_splits=n_inner_cv_splits)\n",
    "            print(f\"      Inner CV: GroupKFold với {n_inner_cv_splits} splits\")\n",
    "            current_groups_for_inner_cv = groups_train_outer\n",
    "        else: # Nếu X_train_outer chỉ còn dữ liệu từ 1 pin hoặc không có group info rõ ràng\n",
    "            inner_cv = KFold(n_splits=n_inner_cv_splits, shuffle=True, random_state=42)\n",
    "            print(f\"      Inner CV: KFold với {n_inner_cv_splits} splits\")\n",
    "            current_groups_for_inner_cv = None # KFold không cần groups\n",
    "\n",
    "\n",
    "        # GridSearchCV cho base learner hiện tại\n",
    "        # Giảm verbosity và n_jobs để tránh quá nhiều output khi test\n",
    "        grid_search_cv = GridSearchCV(\n",
    "            estimator=clone(model_template), # Quan trọng: clone template\n",
    "            param_grid=param_grid_learner,\n",
    "            scoring='neg_root_mean_squared_error', # Hoặc 'r2'\n",
    "            cv=inner_cv,\n",
    "            n_jobs=1, # Đặt là 1 để dễ debug, tăng lên nếu muốn song song\n",
    "            verbose=0 # Đặt là 1 hoặc 2 để xem chi tiết hơn\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            if X_train_outer.empty and learner_name == 'gpr':\n",
    "                raise ValueError(\"X_train_outer rỗng cho GPR.\")\n",
    "            grid_search_cv.fit(X_train_outer, y_train_outer, groups=current_groups_for_inner_cv)\n",
    "\n",
    "            best_model_for_fold = grid_search_cv.best_estimator_\n",
    "            fold_preds = best_model_for_fold.predict(X_val_outer)\n",
    "            oof_predictions_base[val_idx_outer, i_learner] = fold_preds\n",
    "\n",
    "            print(f\"Best params cho {learner_name}: {grid_search_cv.best_params_}\")\n",
    "            print(f\"Best CV score (neg_RMSE): {grid_search_cv.best_score_:.4f}\")\n",
    "            best_params_per_fold_learner.append({\n",
    "                'outer_fold': fold_idx_outer + 1,\n",
    "                'learner': learner_name,\n",
    "                'best_params': grid_search_cv.best_params_,\n",
    "                'best_cv_score': grid_search_cv.best_score_\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"      LỖI với GridSearchCV cho {learner_name}: {e}\")\n",
    "            oof_predictions_base[val_idx_outer, i_learner] = np.nan # Gán NaN nếu GridSearch lỗi\n",
    "\n",
    "        end_time_learner_fold = time.time()\n",
    "        print(f\"      Thời gian cho {learner_name} ở fold này: {end_time_learner_fold - start_time_learner_fold:.2f} giây\")\n",
    "\n",
    "\n",
    "end_time_total_lobo = time.time()\n",
    "print(f\"\\nHoàn thành tạo OOF predictions với GridSearchCV. Tổng thời gian: {end_time_total_lobo - start_time_total_lobo:.2f} giây\")\n",
    "\n",
    "best_params_df = pd.DataFrame(best_params_per_fold_learner)\n",
    "print(\"\\n--- Siêu tham số tốt nhất cho Base Learners ở mỗi Outer Fold ---\")\n",
    "print(best_params_df)\n",
    "\n",
    "\n",
    "meta_features_from_oof = pd.DataFrame(oof_predictions_base, columns=[name for name, _ in base_learner_templates])\n",
    "for col in meta_features_from_oof.columns: # Xử lý NaN\n",
    "    if meta_features_from_oof[col].isnull().any():\n",
    "        print(f\"Cảnh báo: Tìm thấy NaN trong OOF predictions của {col}. Điền bằng giá trị trung bình.\")\n",
    "        if not meta_features_from_oof[col].isnull().all():\n",
    "            meta_features_from_oof[col].fillna(meta_features_from_oof[col].mean(), inplace=True)\n",
    "        else:\n",
    "            meta_features_from_oof[col].fillna(0, inplace=True)\n",
    "\n",
    "meta_target_for_training = pd.Series(oof_true_targets_for_meta, name=target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BƯỚC 3: TINH CHỈNH SIÊU THAM SỐ CHO META-LEARNER (Ridge Regression) ---\n",
    "print(\"\\n--- Tinh chỉnh siêu tham số cho Meta-Learner (Ridge) ---\")\n",
    "meta_learner_template = Ridge(random_state=42)\n",
    "param_grid_meta = param_levels['ridge'][current_level_to_try] # Lấy alpha grid cho level hiện tại\n",
    "\n",
    "# CV cho meta-learner: có thể dùng KFold hoặc LOBO (nếu muốn chặt chẽ)\n",
    "# Ở đây dùng LOBO để nhất quán\n",
    "# Chú ý: groups ở đây là groups gốc, tương ứng với thứ tự của meta_features_from_oof\n",
    "cv_meta = LeaveOneGroupOut()\n",
    "# Hoặc KFold đơn giản hơn: cv_meta = KFold(n_splits=min(5, n_outer_splits), shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_search_meta = GridSearchCV(\n",
    "    estimator=meta_learner_template,\n",
    "    param_grid=param_grid_meta,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=cv_meta, # Sử dụng LOBO với groups gốc\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_meta.fit(meta_features_from_oof, meta_target_for_training, groups=groups) # Truyền groups cho LOBO\n",
    "\n",
    "best_meta_learner = grid_search_meta.best_estimator_\n",
    "print(f\"\\nMeta-Learner tốt nhất: {best_meta_learner}\")\n",
    "print(f\"Hệ số của Meta-Learner tốt nhất: {best_meta_learner.coef_}\")\n",
    "print(f\"Best CV score (neg_RMSE) cho Meta-Learner: {grid_search_meta.best_score_:.4f}\")\n",
    "\n",
    "\n",
    "# --- BƯỚC 4: ĐÁNH GIÁ MÔ HÌNH STACKING VỚI META-LEARNER ĐÃ TINH CHỈNH ---\n",
    "# Dự đoán trên OOF data bằng meta-learner tốt nhất\n",
    "stacking_oof_predictions = best_meta_learner.predict(meta_features_from_oof)\n",
    "oof_rmse_stacking = np.sqrt(mean_squared_error(meta_target_for_training, stacking_oof_predictions))\n",
    "oof_r2_stacking = r2_score(meta_target_for_training, stacking_oof_predictions)\n",
    "oof_mae_stacking = mean_absolute_error(meta_target_for_training, stacking_oof_predictions)\n",
    "print(f\"\\n--- Chỉ số đánh giá của Mô hình STACKING (với Meta-Learner đã tinh chỉnh) trên OOF predictions ---\")\n",
    "print(f\"  RMSE: {oof_rmse_stacking:.4f}\")\n",
    "print(f\"  R2 score: {oof_r2_stacking:.4f}\")\n",
    "print(f\"  MAE: {oof_mae_stacking:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vẽ đồ thị cho meta-learner (giữ nguyên phần này vì nó hữu ích)\n",
    "fig_meta_learner, axes_meta_learner = plt.subplots(n_outer_splits, 1,\n",
    "                                                   figsize=(8, 15),\n",
    "                                                   sharey=True, constrained_layout=True)\n",
    "if n_outer_splits == 1:\n",
    "    axes_meta_learner = [axes_meta_learner]\n",
    "fig_meta_learner.suptitle('Meta Learner (Stacking) Predictions vs Actual (trên OOF data, theo Pin)', fontsize=18, y=1.03)\n",
    "unique_batteries = groups.unique()\n",
    "for i, battery_id_to_plot in enumerate(unique_batteries):\n",
    "    battery_mask = (groups == battery_id_to_plot).values\n",
    "    x_plot_values_batt = df_scaled[battery_mask][cycle_plot_column].values\n",
    "    actual_batt = meta_target_for_training[battery_mask]\n",
    "    predicted_batt_stacking = stacking_oof_predictions[battery_mask]\n",
    "    # Tính R-squared\n",
    "    r2 = r2_score(actual_batt, predicted_batt_stacking)\n",
    "\n",
    "    # Tính MAE\n",
    "    mae = mean_absolute_error(actual_batt, predicted_batt_stacking)\n",
    "\n",
    "    # Tính RMSE\n",
    "    rmse = mean_squared_error(actual_batt, predicted_batt_stacking, squared=False)\n",
    "\n",
    "    print(f\"R-squared: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    ax_meta = axes_meta_learner[i]\n",
    "    ax_meta.plot(x_plot_values_batt, actual_batt, label='Actual SOH', marker='.', linestyle='-', markersize=6)\n",
    "    ax_meta.plot(x_plot_values_batt, predicted_batt_stacking, label='Stacking Predicted SOH', marker='x', linestyle='--', markersize=6)\n",
    "    ax_meta.set_title(f'Stacking Model - Pin: {battery_id_to_plot}', fontsize=12)\n",
    "    ax_meta.set_xlabel(cycle_plot_column, fontsize=10)\n",
    "    ax_meta.set_ylabel('SOH', fontsize=10)\n",
    "    ax_meta.legend(fontsize=9)\n",
    "    ax_meta.grid(True, linestyle=':', alpha=0.5)\n",
    "    ax_meta.tick_params(axis='both', which='major', labelsize=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
